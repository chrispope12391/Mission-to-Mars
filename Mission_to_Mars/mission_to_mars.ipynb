{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "new_browser = Browser('chrome', **executable_path, headless=False)\n",
    "valles_browser = Browser('chrome', **executable_path, headless=False)\n",
    "cerb_browser = Browser('chrome', **executable_path, headless=False)\n",
    "schia_browser = Browser('chrome', **executable_path, headless=False)\n",
    "syrt_browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nasa Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store website\n",
    "\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements that contain mars article information\n",
    "mars_results = soup.find_all('div', class_='col-md-8')\n",
    "\n",
    "mars_title = []\n",
    "mars_teaser = []\n",
    "\n",
    "# Identify the title and teaser article in each article\n",
    "for result in mars_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title\n",
    "        title = result.find('div', class_='content_title').text\n",
    "        #identify and return the teaser article\n",
    "        teaser = result.find('div', class_='article_teaser_body').text\n",
    "        mars_title.append(title)\n",
    "        mars_teaser.append(teaser)\n",
    "        \n",
    "        #Print title and teaser article\n",
    "        if (title and teaser):\n",
    "            \n",
    "            print('-------------------------------------------')\n",
    "            print(title)\n",
    "            print(teaser)\n",
    "            \n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store featured image website\n",
    "\n",
    "image_url = \"https://spaceimages-mars.com/\"\n",
    "new_browser.visit(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "new_html = new_browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "new_soup = BeautifulSoup(new_html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements that contain header image information\n",
    "image_results = new_soup.find_all('img', class_='headerimage fade-in')\n",
    "image_results\n",
    "\n",
    "#store featured URL info\n",
    "featured_url = []\n",
    "\n",
    "\n",
    "# Identify the featured image url\n",
    "for result in image_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title\n",
    "        featured_img = result['src']\n",
    "\n",
    "        featured_url.append(featured_img)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store featured image in a variable\n",
    "\n",
    "featured_image_url = \"https://spaceimages-mars.com/\" + featured_url[0]\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_url = \"https://galaxyfacts-mars.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas's \"read_html\"\n",
    "\n",
    "tables = pd.read_html(facts_url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the table to a dataframe\n",
    "\n",
    "facts_df = tables[1]\n",
    "# facts_df.columns = ['']\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create urls for each hemisphere\n",
    "\n",
    "hemi_url = \"https://marshemispheres.com/\"\n",
    "valles_url = hemi_url +\"valles.html\"\n",
    "cerbrus_url = hemi_url +\"cerberus.html\"\n",
    "schia_url = hemi_url +\"schiaparelli.html\"\n",
    "syrt_url = hemi_url +\"syrtis.html\"\n",
    "\n",
    "valles_browser.visit(valles_url)\n",
    "cerb_browser.visit(cerbrus_url)\n",
    "schia_browser.visit(schia_url)\n",
    "syrt_browser.visit(syrt_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "valles_html = valles_browser.html\n",
    "cerb_html = cerb_browser.html\n",
    "schia_html = schia_browser.html\n",
    "syrt_html = syrt_browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "valles_soup = BeautifulSoup(valles_html, 'html.parser')\n",
    "cerb_soup = BeautifulSoup(cerb_html, 'html.parser')\n",
    "schia_soup = BeautifulSoup(schia_html, 'html.parser')\n",
    "syrt_soup = BeautifulSoup(syrt_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all elements that contain hemisphere info\n",
    "valles_results = valles_soup.find_all('div', class_=\"container\")\n",
    "cerb_results = cerb_soup.find_all('div', class_=\"container\")\n",
    "schia_results = schia_soup.find_all('div', class_=\"container\")\n",
    "syrt_results = syrt_soup.find_all('div', class_=\"container\")\n",
    "\n",
    "\n",
    "#create list to store title and hemi_image_url\n",
    "hemi_title = []\n",
    "hemi_image_url = []\n",
    "\n",
    "\n",
    "# Identify the hemishphere title and image url\n",
    "for result in valles_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title and image\n",
    "        valles_name = result.find('h2', class_=\"title\").text\n",
    "        valles_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(valles_name)\n",
    "        hemi_image_url.append(hemi_url+valles_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the hemishphere title and image url\n",
    "for result in cerb_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "         #identify and return the title and image\n",
    "        cerb_name = result.find('h2', class_=\"title\").text\n",
    "        cerb_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(cerb_name)\n",
    "        hemi_image_url.append(hemi_url+cerb_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the hemishphere title and image url\n",
    "for result in schia_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title and image\n",
    "        schia_name = result.find('h2', class_=\"title\").text\n",
    "        schia_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(schia_name)\n",
    "        hemi_image_url.append(hemi_url+schia_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the hemishphere title and image url\n",
    "for result in syrt_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title and image\n",
    "        syrt_name = result.find('h2', class_=\"title\").text\n",
    "        syrt_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(syrt_name)\n",
    "        hemi_image_url.append(hemi_url+syrt_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary of mars hemispheres and url to large image\n",
    "\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": hemi_title[0], \"img_url\": hemi_image_url[0]},\n",
    "    {\"title\": hemi_title[1], \"img_url\": hemi_image_url[1]},\n",
    "    {\"title\": hemi_title[2], \"img_url\": hemi_image_url[2]},\n",
    "    {\"title\": hemi_title[3], \"img_url\": hemi_image_url[3]},\n",
    "]\n",
    "hemisphere_image_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
